{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, Input\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import csv\n",
    "import os,random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM, Input\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.core import Dropout, Activation, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(temp):\n",
    "    min_len = 3000\n",
    "    for i in range(11):\n",
    "        j = 0\n",
    "        while temp[j][i] != '' and j<len(temp)-1:\n",
    "            j+=1\n",
    "        min_len = min(min_len, j);\n",
    "#     print(min_len)\n",
    "    return temp[:min_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.ragged import constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../po-cf-ex-1-features/E_ID8.csv\", 'r') as f:\n",
    "    temp = list(csv.reader(f, delimiter = \",\"))\n",
    "temp = process(temp)\n",
    "for i in range(len(temp)):\n",
    "    for j in range(len(temp[0])):\n",
    "        if temp[i][j]=='':\n",
    "            print(i,j)\n",
    "# E_ID8 343,I was Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "(490, 11)\n",
      "(889, 11)\n",
      "(464, 11)\n",
      "(537, 11)\n",
      "(981, 11)\n",
      "(682, 11)\n",
      "(546, 11)\n",
      "(865, 11)\n",
      "(1119, 11)\n",
      "(784, 11)\n",
      "(637, 11)\n",
      "(576, 11)\n",
      "(420, 11)\n",
      "(505, 11)\n",
      "(933, 11)\n",
      "(587, 11)\n",
      "(422, 11)\n",
      "(913, 11)\n",
      "(838, 11)\n",
      "(739, 11)\n",
      "(584, 11)\n",
      "(553, 11)\n",
      "(503, 11)\n",
      "(492, 11)\n",
      "(536, 11)\n",
      "(505, 11)\n",
      "(555, 11)\n",
      "(897, 11)\n",
      "(1079, 11)\n",
      "(905, 11)\n",
      "(1120, 11)\n",
      "(612, 11)\n",
      "(520, 11)\n",
      "(402, 11)\n",
      "(492, 11)\n",
      "(699, 11)\n",
      "(429, 11)\n",
      "(299, 11)\n",
      "(553, 11)\n",
      "(823, 11)\n",
      "(988, 11)\n",
      "(768, 11)\n",
      "(802, 11)\n",
      "(883, 11)\n",
      "(1500, 11)\n",
      "(562, 11)\n",
      "(606, 11)\n",
      "(384, 11)\n",
      "(762, 11)\n",
      "(511, 11)\n",
      "(608, 11)\n",
      "(798, 11)\n",
      "(2472, 11)\n",
      "(684, 11)\n",
      "(273, 11)\n",
      "(691, 11)\n",
      "(1207, 11)\n",
      "(390, 11)\n",
      "(959, 11)\n",
      "(1079, 11)\n",
      "(988, 11)\n",
      "(1144, 11)\n",
      "(581, 11)\n",
      "(487, 11)\n",
      "(1206, 11)\n",
      "(766, 11)\n",
      "(1528, 11)\n",
      "(377, 11)\n",
      "(553, 11)\n",
      "(444, 11)\n",
      "(461, 11)\n",
      "(590, 11)\n",
      "(484, 11)\n",
      "(525, 11)\n",
      "(438, 11)\n",
      "(643, 11)\n",
      "(517, 11)\n",
      "(685, 11)\n"
     ]
    }
   ],
   "source": [
    "types = {'B_ID':8, 'E_ID':17, 'NE_ID':27, 'S_ID':10, 'P_ID':16}\n",
    "x_val = []\n",
    "x_id = []\n",
    "for ids, vals in types.items():\n",
    "    for i in range(1,vals+1):\n",
    "        x_id.append(ids + str(i))\n",
    "        try: \n",
    "            with open(\"../po-cf-ex-1-features/\"+ids+str(i)+\".csv\", 'r') as f:\n",
    "                temp = list(csv.reader(f, delimiter = \",\"))\n",
    "            temp = process(temp)\n",
    "            temp = np.asarray(temp)\n",
    "            temp = temp.astype(np.float64)\n",
    "        except:\n",
    "            print(\"Problem in:\", ids, i)\n",
    "            continue\n",
    "        x_val.append(temp)\n",
    "# x_val = np.asarray(sequence.pad_sequences(x_val, maxlen=2500)).astype(np.float64)\n",
    "print(len(x_val))\n",
    "for i in range(len(x_val)):\n",
    "    print(x_val[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of CF:  (78,)\n",
      "shape of PO:  (78,)\n",
      "shape of TS:  (78,)\n",
      "24\n",
      "[41.         38.         28.21008112 33.3397327  44.33333333 45.33333333\n",
      " 40.33333333 44.33333333 48.33333333 49.33333333 42.66666667 44.66666667\n",
      " 46.         46.66666667 50.         48.66666667 50.         48.33333333\n",
      " 50.         50.         46.33333333 44.         50.         47.\n",
      "         nan 39.66666667 41.         44.33333333 46.33333333 40.66666667\n",
      " 43.66666667 42.         40.         42.         34.         46.\n",
      " 40.         50.         50.         45.         47.         47.\n",
      " 38.         50.         46.         46.         43.         41.\n",
      " 50.         47.         49.         49.         27.         34.\n",
      " 44.         26.         32.89508774 38.41075339 26.66666667 36.\n",
      " 26.33333333 33.66666667 48.         27.         50.         14.\n",
      " 33.         50.         22.         32.         40.         34.3081805\n",
      " 14.66666667 35.66666667 36.66666667 36.         27.66666667 37.        ]\n"
     ]
    }
   ],
   "source": [
    "po_val = []\n",
    "cf_val = []\n",
    "for ids in x_id:\n",
    "    try:\n",
    "        df = pd.read_excel(\"../KiMoRe/\"+ids+\"/Es1/Label/ClinicalAssessment_\"+ids+\".xlsx\")\n",
    "    except:\n",
    "        print(\"problem in: \", ids)\n",
    "        continue\n",
    "    df = np.array(df).reshape((16,))\n",
    "    po_val.append(df[6])\n",
    "    cf_val.append(df[11])\n",
    "po_val = np.asarray(po_val).astype(np.float64)\n",
    "cf_val = np.asarray(cf_val).astype(np.float64)\n",
    "ts_val = po_val+cf_val\n",
    "print(\"shape of CF: \", cf_val.shape)\n",
    "print(\"shape of PO: \", po_val.shape)\n",
    "print(\"shape of TS: \", ts_val.shape)\n",
    "# print(po_val)\n",
    "for i in range(len(ts_val)):\n",
    "    if np.isnan(ts_val[i]):\n",
    "        print(i)\n",
    "print(ts_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jumble_up(val):\n",
    "    return np.random.permutation(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30 21 42 35 10 37  5 25 28 59  0 58 62 45 57 56 16 60 64 13 70 44 36 29\n",
      " 76 55 15 32 68 34 74 14 53 38 63 26 18 49 43 65 12 33 31  4 73 52  7 48\n",
      "  8 20  3 51 66 47 17 46 19 69 67 11 40 41  2 50 22 71 27  1 24 77 54  6\n",
      "  9 72 75 39 61 23]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(ts_val))\n",
    "indices = jumble_up(indices)\n",
    "print(indices)\n",
    "temp_x = x_val\n",
    "temp_ts = ts_val\n",
    "for i in range(len(ts_val)):\n",
    "    x_val[i] = temp_x[indices[i]]\n",
    "    ts_val[i] = temp_ts[indices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96       0.74       0.52666667 0.8        1.         0.76\n",
      " 0.85333333 0.81333333 1.         0.52666667 1.         0.73333333\n",
      " 0.53333333 1.         0.52666667 0.92       0.8        0.71333333\n",
      " 0.88       0.76821507 0.79333333 0.79333333 0.92       0.85333333\n",
      " 0.72       0.44       0.96       1.         0.28       0.88\n",
      " 0.53333333 0.8        0.79333333 0.81333333 0.87333333 0.65790175\n",
      " 0.54       0.96       1.         0.92       0.8        0.72\n",
      " 0.72       0.55333333 0.87333333 1.         0.92666667 1.\n",
      " 1.         0.8        0.98       1.         0.8        1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-81177675099c>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_val = x_val/max_x_val\n"
     ]
    }
   ],
   "source": [
    "# x_val /= np.max(np.abs(x_val))\n",
    "# ts_val /= np.max(np.abs(ts_val))\n",
    "max_x_val = -1\n",
    "max_ts_val = -1\n",
    "for i in range(len(ts_val)):\n",
    "    max_x_val = max(max_x_val, np.max(np.abs(x_val[i])))\n",
    "    max_ts_val = max(max_ts_val, np.max(np.abs(ts_val[i])))\n",
    "x_val = x_val/max_x_val\n",
    "ts_val = ts_val/max_ts_val\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_val,ts_val, test_size=0.3)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 600 \n",
    "nr = 78   \n",
    "n_dim = 11  \n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    n=-1\n",
    "    while n<53:\n",
    "        n+=1\n",
    "        xt = np.array(x_train[n])\n",
    "        yt = np.array(y_train[n])\n",
    "        yield xt,yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(100, 5, padding ='same', strides = 2, input_shape = (None,n_dim)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Convolution1D(30, 3, padding ='same', strides = 2))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Convolution1D(10, 3, padding ='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Convolution1D(16, 1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution1D(8, 1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # reduce the number of dimensions to the number of classes\n",
    "    model.add(Convolution1D(1, 1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    print(model.summary())\n",
    "\n",
    "#     model.add(Flatten())\n",
    "\n",
    "#     model.add(Dense(200))\n",
    "#     model.add(LeakyReLU())\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     model.add(Dense(100))\n",
    "#     model.add(LeakyReLU())\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     model.add(Dense(1))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    # Early stopping if the validaton Loss does not decrease for 100 epochs\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience = 100)\n",
    "\n",
    "    t = now()\n",
    "    history = model.fit_generator(train_generator(),steps_per_epoch=10, epochs=500, verbose=1,\n",
    "                     callbacks = [early_stopping])\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(1)\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Training Loss')\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Validation Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the prediction of the CNN model for the training and validation sets\n",
    "    pred_train = model.predict(x_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "\n",
    "    plt.figure(figsize = (8,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(pred_train,'s', color='red', label='Prediction', linestyle='None', alpha = 0.5, markersize=6)\n",
    "    plt.plot(y_train,'o', color='green',label='Quality Score', alpha = 0.4, markersize=6)\n",
    "    plt.ylim([-0.1,1.1])\n",
    "    plt.title('Training Set',fontsize=18)\n",
    "    plt.xlabel('Sequence Number',fontsize=16)\n",
    "    plt.ylabel('Quality Scale',fontsize=16)\n",
    "    plt.legend(loc=3, prop={'size':14}) # loc:position\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(pred_test,'s', color='red', label='Prediction', linestyle='None', alpha = 0.5, markersize=6)\n",
    "    plt.plot(y_test,'o', color='green',label='Quality Score', alpha = 0.4, markersize=6)\n",
    "    plt.title('Testing Set',fontsize=18)\n",
    "    plt.ylim([-0.1,1.1])\n",
    "    plt.xlabel('Sequence Number',fontsize=16)\n",
    "    plt.ylabel('Quality Score',fontsize=16)\n",
    "    plt.legend(loc=3, prop={'size':14}) # loc:position\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig('../../Results/CNN_Vicon_Scores.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Calculate the cumulative deviation and rms deviation for the validation set\n",
    "    test_dev = abs(np.squeeze(pred_test)-y_test)\n",
    "    # Cumulative deviation\n",
    "    mean_abs_dev = np.mean(test_dev)\n",
    "    # RMS deviation\n",
    "    rms_dev = sqrt(mean_squared_error(pred_test, y_test))\n",
    "    print('Mean absolute deviation:', mean_abs_dev)\n",
    "    print('RMS deviation:', rms_dev)\n",
    "    \n",
    "    return mean_abs_dev, rms_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, None, 100)         5600      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, None, 30)          9030      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, None, 30)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, None, 30)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, None, 10)          910       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, None, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, None, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, None, 16)          176       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, None, 8)           136       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, None, 1)           9         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, None, 1)           0         \n",
      "=================================================================\n",
      "Total params: 15,861\n",
      "Trainable params: 15,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:234 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_11 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8c06185091c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMean_abs_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMS_dev\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-1be7a75e1245>\u001b[0m in \u001b[0;36mNetwork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     history = model.fit_generator(train_generator(),steps_per_epoch=10, epochs=500, verbose=1,\n\u001b[0m\u001b[1;32m     46\u001b[0m                      callbacks = [early_stopping])\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/yash/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:234 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_11 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, None)\n"
     ]
    }
   ],
   "source": [
    "Mean_abs_dev, RMS_dev  = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phy-rehab",
   "language": "python",
   "name": "phy-rehab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
